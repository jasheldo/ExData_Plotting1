submit()
evalute(sd,c(1.4,3.6,7.9,8.8))
evalute(sd(),c(1.4,3.6,7.9,8.8))
View(evaluate)
evaluate <- function(func, dat){
sd(),c(1.4,3.6,7.9,8.8)
evalue(sd(),c(1.4,3.6,7.9,8.8))
evaluate(sd(),c(1.4,3.6,7.9,8.8))
evaluate(sd,c(1.4,3.6,7.9,8.8))
evaluate(function(x){x+1},6)
evaluate(function(x){x[1]},c(8,4,0))
evaluate(function(x){x[length(x)]},c(8,4,0))
?paste
paste("Programming", "is", "fun!")
submit()
telegram("Poop is an amazing thing.  I'm glad it happens.")
submit()
submit()
submit()
mad_libs("Boston", "happy", "faggot")
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
'I' %p% 'love' %p% 'R!'
d1 <- Sys.Date()
class(d1)
unclass
unclass(d1)
d1
d2 <- as.Date("1969-01-01")
unclass(d2)
t1<-Sys.time()
t1
class(t1)
unclass(t1)
t2<-as.POSIXlt(Sys.time())
class(t2)
unclass(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(d1)
months(t1)
quarters(t2)
t3 <- "October 17, 1986 08:24"
strptime(t3,"%B %d, %Y %H:%M")
strptime(t3, "%B %d, %Y %H:%M")
t4<-strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time() > t1
Sys.time() - t1
difftime(Sys.time(),t1,units = 'days')
q()
load("swirl")
load(swirl)
library("swirl", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages(c("cluster", "Matrix", "nlme", "openssl", "survival"))
library("swirl", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install_from_swirl("Getting and Cleaning Data")
swirl()
fileUrl<- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/cameras.csv", method="curl")
getwd()
download.file(fileUrl,destfile="./data/cameras.csv", method="curl")
cameraData <- read.table("./data/cameras.csv", sep=",",header= TRUE)
head(cameraData)
fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.xlsx?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/cameras.xlsx", method="curl")
dateDownloaded<- date()
library(xlsx)
install.packages("xlsx")
library("xlsx")
cameraData <- read.xlsx("./data/cameras.xlsx",sheetIndex = 1, header = TRUE)
head(cameraData)
library(XML)
install.packages("XML")
library(XML)
fileUrl <- "http://www.w3scools.com/xml/simple.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
doc
fileUrl <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileURL,useInternal=TRUE)
doc <- htmlTreeParse(fileUrl,useInternal=TRUE)
scores <- xpathSApply(doc,"//li[@class='score']",xmlValue)
teams <- xpathSApply(doc,"//li[@class='team-name']",xmlValue)
scores
teams
install.packages("jsonlite")
library(jsonlite)
install.packages("data.table")
library(data.table)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl,destfile="./data/communities.csv", method="curl")
communities <- data.table("./data/communities.csv")
setkey(communities,VAL)
head(communities)
rm(communtities)
rm(communities)
rm(dataDownloaded)
rm(dataDownloaded)
rm(dateDownloaded)
rm(doc)
rm(rootNode)
rm(teams)
rm(scores)
communities <- data.frame
communities <- read.csv("./data/communities.csv")
communities
head(communities)
communities2 <- data.table(communities)
head(communities2)
setkey(communities2,VAL)
communities2[,.N,by=VAL]
communities2[FES]
communities2[,FES]
rm(communities2)
rm(communities)
rm(cameraData)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl,"./data/NGAP.xlsx", method="curl")
colIndex <- 7:15
rowIndex <- 18:23
data <- read.xlsx("./data/NGAP.xlsx", sheetIndex = 1, colIndex = colIndex, rowIndex = rowIndex)
sum(data$Zip*data$Ext,na.rm=T)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
doc <- xmlTreeParse(fileUrl,useInternal=TRUE,method="curl")
download.file(fileUrl,"./data/restaurants.xml",method="curl")
doc <- xmlTreeParse("./data/restaurants.xml",useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
head(doc)
doc <- xmlTreeParse("./data/restaurants.xml",useInternalNodes=TRUE)
head(doc)
doc <- xmlTreeParse("./data/restaurants.xml")
head(doc)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
xmlSApply(rootNode, "//zipcode", xlmValue)
doc <- xmlParse("./data/restaurants.xml")
xml_data <- xmlToList(doc)
zip <- as.list(xml_data[["zipcode"]])
zip
doc <- xmlTreeParse("./data/restaurants.xml")
class(doc)
xlmtop = xlmRoot(doc)
xmltop = xmlRoot(doc)
class(xmltop)
xmlName(xmltop)
xmlSize(xmltop)
smlName(xmltop[[1]])
xmlName(xmltop[[1]])
xmltop[[1]]
names(doc[[1]])
xmlSize(xmltop[[1]])
xmlSapply(xmltop[[1]])
xmlSApply(xmltop[[1]])
xmlSApply(xmltop[[1]],xmlName)
xmlSApply(xmltop[[1]],xmlAttrs)
xmlSApply(xmltop[[1]],xmlSize)
xmltop[[1]][[1]]
xmltop[[1]][[2]]
xmltop[[2]][[1]]
xmltop[[2]][[2]]
xmltop[[1]][[3]]
xmltop[[1]][[1]][[1]]
xmltop[[1]][[1]][[1]][[1]]
xmltop[[1]][[1]][[1]][[1]][[1]]
xmltop[[1]][[1]][[1]]
xmltop[[1]][[1]]
xmlSApply(xmltop,"//zipcode",xmlValue)
xmlSApply(xmltop,xmlValue)
xmlSApply(xmltop[[1]],"//zipcode",xmlValue)
xpathSApply(xmltop,"//zipcode",xmlValue)
zipcode <- xpathSApply(xmltop,"//zipcode",xmlValue)
my.doc <- xmlTreeParse(file="./data/restaurants.xml",useInternal=TRUE)
root.Node <- xmlRoot(my.doc)
xmlName(root.Node)
zipcode <- xpathSApply(root.Node,"//zipcode",xmlValue)
length(zipcode[zipcode==21231])
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl,"./data/PID.csv",method="curl")
DT <- fread(input="./data/PID.csv",sep=",")
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(rowMeans(DT)[DT$SEX==1];rowMeans(DT)[DT$SEX==2])
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15), mean(DT[DT$SEX==2,]$pwgtp15))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(rowMeans(DT)[DT$SEX==1], rowMeans(DT)[DT$SEX==2])
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(mean(DT[DT$SEX==1,]$pwgtp15), mean(DT[DT$SEX==2,]$pwgtp15))
tapply(DT$pwgtp15,DT$SEX,mean)
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
library(dplyr)
?readRDS
download.file("github.com/DataScienceSpecialization/courses/blob/master/03_GettingData/dplyr/chicago.rds","./data/chicago.rds")
chicago <- readRDS("./data/chicago.rds")
chicago <- readRDS(./data/chicago.rds)
chicago <- readRDS(/data/chicago.rds)
chicago <- readRDS(chicago.rds)
setwd("~/data")
chicago <- readRDS(chicago.rds)
chicago <- readRDS("chicago.rds")
ls
getwd()
chicago <- readRDS("chicago.rds")
chicago <- readRDS("./chicago.rds")
download.file("github.com/DataScienceSpecialization/courses/blob/master/03_GettingData/dplyr/chicago.rds","./data/chicago.rds", method = "curl", extra = '-L')
setwd("~/")
download.file("github.com/DataScienceSpecialization/courses/blob/master/03_GettingData/dplyr/chicago.rds","./data/chicago.rds", method = "curl", extra = '-L')
chicago <- readRDS("./data/chicago.rds")
download.file("https://github.com/DataScienceSpecialization/courses/blob/master/03_GettingData/dplyr/chicago.rds","./data/chicago.rds", method = "curl", extra = '-L')
chicago <- readRDS("./data/chicago.rds")
chicago <- readRDS("./data/chicago.rds")
str(chicago)
names(chicago)
head(select(chciago, city:dptp))
head(select(chicago, city:dptp))
head(select(chicago, -(city:dptp)))
i <- meatch("city",names(chicago))
i <- match("city",names(chicago))
j<- match("dptp",names(chicago))
head(chicago[,(i:j)])
chic.f <- filter(chicago,pm25tmean2>30)
chic.f
chic.f <- filter(chicago,pm25tmean2>30 & tmpd > 80)
head(chic.f)
chicago <- arrange(chicago, date)
head(chicago)
tail(chicago)
chicago <- arrange(chicago, desc(date))
head(chicago)
tail(chicago)
chicago <- rename(chicago, mp25 = pm25tmean2, dewpoint = dptp)
head(chicago)
chicago <- mutate(chicago, pm25detrend = mp25-mean(mp25, na.rm=TRUE))
head(select(chicago,mp25,pm25detrend))
chicago <- mutate(chicago, tempcat = factor(1*(tmpd>80), labels = c("cold","hot")))
hotcold <- group_by(chicago, tempcat)
hotcold
summarize(hotcold,mp25=mean(mp25),o3=max(o3tmean2),na2=median(no2tmean2))
summarize(hotcold,mp25=mean(mp25,na.rm=TRUE),o3=max(o3tmean2),na2=median(no2tmean2))
chicago <- mutate(chicago, year = as.POSIXlt(date)$year + 1900)
years <- group_by(chicago, year)
fileUrl1="https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
filrUrl2 = "https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
download.file(fileUrl1,destfile="./data/reviews.csv",method="curl")
download.file(fileUrl2,destfile="./data/solutions.csv",method="curl")
download.file(filrUrl2,destfile="./data/solutions.csv",method="curl")
reviews = read.csv("./data/reviews.csv")
solutions = read.csv("./data/solutions.csv")
head(reviews,2)
mergedData = merge(reviews, solutions, by.x = "solution_id", by.y = "id", all = TRUE)
head(mergedData)
swirl()
library(swirl)
install.packages(c("BH", "survival"))
q()
library(swirl)
install.packages("swirl")
library(swirl)
swirl()
install_from_swirl("getting_and_Cleaning_Data")
install_from_swirl("Getting_and_Cleaning_Data")
swirl()
mydf <- read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time
)
-5:20
-(5:20)
select(cran, -(X:size))
fliter(cran, package == "swirl")
filter(cran, package == "swirl")
filter(cran, r_version =="3.1.1", country == "US")
?Comparison
filter(cran, r_version <="3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500 & R_os == "Linux-gnu")
filter(cran, size > 100500 & r_os == "linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
order(cran2, ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
tbl, pack_sum
tbl
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- fliter(pack_sum, count > 679)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorter <- arrange(top_unique, desc(unique))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students,sex, count, -grade)
students2
res <- gather(students2, sex_class, count)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(data = res, col = sex_class, into = c("sex", "class"))
reset()
swirl()
submit()
students3
submit()
?spread
submit()
extract_numeric("class5")
submit()
submit()
submit()
submit()
students4
submit()
submit()
submit()
submit()
passed
failed
passed <- mutate(passed, status = "passed")
failed <- mutate(failed, status = "failed")
bind_rows(passed, failed)
sat
submit()
submit()
submit()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "./data/hid.csv")
library(dplyr)
library(data.table)
install.packages("data.table")
library(data.table)
hid <- read.csv("./data/hid.csv")
head(hid)
logical <- hid$ACR == 3 & data1$AGS == 6
logical <- hid$ACR == 3 & hid$AGS == 6
head(which(logical),3)
install.packages("jpeg")
library(jpeg)
download.file(https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg, "./data/Fjeff.jpg")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"", "./data/Fjeff.jpg")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", "./data/Fjeff.jpg")
dst2 = './data/Fjeff.jpeg'
quantile(dst2,probs=c(0.3,0.8))
logical
which(logical)
q()
install.packages("lubridate")
library(lubridate)
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
hour(this_moment)
ymd("1989-05-17")
mydate <- ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 14, minutes = 17)
this_momeht
this_moment
nyc <- now(tzone = "America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
with_tz
?with_tz
arrive <- with_tz(arrive,tzone = "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?interval
how_long <- interval(last_time, arrive, tzone = attr(last_time, "tzone"))
how_long <- interval(last_time, arrive)
as.period(how_long)
stopwatch()
install.packages(c("DBI", "survival"))
q()
setwd("~/GitHub")
setwd("~/GitHub/ExData_Plotting1")
install.packages(c("jsonlite", "nlme", "survival"))
power <- read.csv("./household_power_consumption.txt", sep = ";")
power <- subset(power, power$Date == "1/2/2007" | power$Date == "2/2/2007")
head(power)
library(lubridate)
x <- dmy("1/2/2007")
x
x <- dmy(power$Date)
x
power$Date <- as.Date(power$Date)
power$Date
power$Date <- x
power$Date
class(power)
slt(power)
sapply(power, mode)
power$Date <- as.Date(power$Date)
sapply(power, mode)
head(power)
strptime(power$Time, format = "%H:%M:%S")
power$Time
class(power$Time)
sapply(power, mode)
hist(power$Global_active_power)
power$Global_active_power <- as.numeric(power$Global_active_power)
sapply(power, mode)
hist(power$Global_active_power)
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts")
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", color = "red", main = "Global Active Power")
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power")
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power")
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power", breaks = 12)
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power", breaks = 10)
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power", breaks = 10)
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power", breaks = 20)
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power", breaks = 19)
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power", breaks = 18)
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power", breaks = 17)
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power", breaks = 16)
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power", breaks = 100)
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power", breaks = 50)
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power", breaks = 25)
hist(power$Global_active_power, xlab = "Global Active Power (kilowatts)", col = "red", main = "Global Active Power")
